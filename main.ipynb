{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1598e0-3bd1-4179-abc5-44714f55c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8863b874-9d85-444f-80b0-c3193d4c1a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # loads .env file\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "print(\"Token loaded:\", HF_TOKEN is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd15012a-acfb-429e-bd30-7558ee765d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b1dc3-1ec5-4aeb-bfd9-4cf6003e572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"RepText\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ae3ba-1484-4c44-8e4e-26e7aaad43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ccf8ff-2d39-4ee5-9ee5-3d93776fe6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1056187-b7e7-4ade-818b-ce7e41b0caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11490154-7ff5-4ddf-baad-90f110ea7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from controlnet_flux import FluxControlNetModel\n",
    "from pipeline_flux_controlnet import FluxControlNetPipeline\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "import os\n",
    "\n",
    "def contains_chinese(text):\n",
    "    if re.search(r'[\\u4e00-\\u9fff]', text):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def canny(img):\n",
    "    low_threshold = 50\n",
    "    high_threshold = 100\n",
    "    img = cv2.Canny(img, low_threshold, high_threshold)\n",
    "    img = img[:, :, None]\n",
    "    img = 255 - np.concatenate([img, img, img], axis=2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec78b2-a889-4d5b-8e03-00c6c7b4ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"black-forest-labs/FLUX.1-dev\"\n",
    "controlnet_model = \"Shakker-Labs/RepText\"\n",
    "\n",
    "controlnet = FluxControlNetModel.from_pretrained(controlnet_model, torch_dtype=torch.bfloat16)\n",
    "pipe = FluxControlNetPipeline.from_pretrained(\n",
    "    base_model, controlnet=controlnet, torch_dtype=torch.bfloat16\n",
    ").to(\"cuda\")\n",
    "\n",
    "## set resolution\n",
    "width, height = 1024, 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfccb56a-1cbb-4a78-bdd9-f3f657ea0ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict(text=[\"hi!!\"],prompt='a street sign in city',num_inference_steps=30,controlnet_conditioning_step=30,image_size=[1024,1024],file_name='result'):\n",
    "    ## set text content, position, color\n",
    "    \n",
    "    ## set resolution\n",
    "    width, height = image_size[0], image_size[1]\n",
    "\n",
    "    ## set font\n",
    "    font_path = \"./assets/Arial_Unicode.ttf\" # use your own font\n",
    "    font_size = 80 # it is recommended to use a font size >= 60\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    ## set text content, position, color\n",
    "    text_list = text\n",
    "    text_position_list = [(370, 200)]\n",
    "    text_color_list = [(255, 255, 255)]\n",
    "\n",
    "    # text_list = [\"Shakker Labs\"]\n",
    "    # text_position_list = [(270, 300)]\n",
    "    # text_color_list = [(255, 255, 255)]\n",
    "\n",
    "    # text_list = [\"Lovart AI\", \"Always Day 1\"]\n",
    "    # text_position_list = [(470, 300), (470, 400)]\n",
    "    # text_color_list = [(255, 255, 255), (255, 255, 255)]\n",
    "\n",
    "    # text_list = [\"以往不谏\", \"来者可追\"]\n",
    "    # text_position_list = [(200, 200), (200, 300)]\n",
    "    # text_color_list = [(255, 255, 255), (255, 255, 255)]\n",
    "\n",
    "    # text_list = [\"Shakker Labs\", \"RepText\"]\n",
    "    # text_position_list = [(200, 200), (200, 300)]\n",
    "    # text_color_list = [(255, 255, 255), (255, 255, 255)]\n",
    "\n",
    "    ## set controlnet conditions\n",
    "    control_image_list = [] # canny list\n",
    "    control_position_list = [] # position list\n",
    "    control_mask_list = [] # regional mask list\n",
    "    control_glyph_all = np.zeros([height, width, 3], dtype=np.uint8) # all glyphs\n",
    "    \n",
    "    ## handle each line of text\n",
    "    for text, text_position, text_color in zip(text_list, text_position_list, text_color_list):\n",
    "\n",
    "        ### glyph image, render text to black background\n",
    "        control_image_glyph = Image.new(\"RGB\", (width, height), (0, 0, 0))\n",
    "        draw = ImageDraw.Draw(control_image_glyph)\n",
    "        draw.text(text_position, text, font=font, fill=text_color)\n",
    "\n",
    "        ### get bbox\n",
    "        bbox = draw.textbbox(text_position, text, font=font)\n",
    "\n",
    "        ### position condition\n",
    "        control_position = np.zeros([height, width], dtype=np.uint8)\n",
    "        control_position[bbox[1]:bbox[3], bbox[0]:bbox[2]] = 255\n",
    "        control_position = Image.fromarray(control_position.astype(np.uint8))\n",
    "        control_position_list.append(control_position)\n",
    "\n",
    "        ### regional mask\n",
    "        control_mask_np = np.zeros([height, width], dtype=np.uint8)\n",
    "        control_mask_np[bbox[1]-5:bbox[3]+5, bbox[0]-5:bbox[2]+5] = 255\n",
    "        control_mask = Image.fromarray(control_mask_np.astype(np.uint8))\n",
    "        control_mask_list.append(control_mask)\n",
    "\n",
    "        ### accumulate glyph\n",
    "        control_glyph = np.array(control_image_glyph)\n",
    "        control_glyph_all += control_glyph\n",
    "\n",
    "        ### canny condition\n",
    "        control_image = canny(cv2.cvtColor(np.array(control_image_glyph), cv2.COLOR_RGB2BGR))\n",
    "        control_image = Image.fromarray(cv2.cvtColor(control_image, cv2.COLOR_BGR2RGB))\n",
    "        control_image_list.append(control_image)\n",
    "        \n",
    "    control_glyph_all = Image.fromarray(control_glyph_all.astype(np.uint8))\n",
    "    control_glyph_all = control_glyph_all.convert(\"RGB\")\n",
    "    # control_glyph_all.save(\"./results/control_glyph.jpg\")\n",
    "\n",
    "    # it is recommended to use words such 'sign', 'billboard', 'banner' in your prompt\n",
    "    # for Englith text, it helps if you add the text to the prompt\n",
    "    for text in text_list:\n",
    "        if not contains_chinese(text):\n",
    "            prompt += f\", '{text}'\"\n",
    "    prompt += \", filmfotos, film grain, reversal film photography\" # optional\n",
    "    print(prompt)\n",
    "\n",
    "    generator = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "\n",
    "    image = pipe(\n",
    "        prompt,\n",
    "        control_image=control_image_list, # canny\n",
    "        control_position=control_position_list, # position\n",
    "        control_mask=control_mask_list, # regional mask\n",
    "        control_glyph=control_glyph_all, # as init latent, optional, set to None if not used\n",
    "        controlnet_conditioning_scale=1.0,\n",
    "        controlnet_conditioning_step=controlnet_conditioning_step,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=3.5,\n",
    "        generator=generator,\n",
    "    ).images[0]\n",
    "\n",
    "    if not os.path.exists(\"./results\"):\n",
    "        os.makedirs(\"./results\")\n",
    "    image.save(f\"./results/{file_name}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c1610-9866-4801-94eb-f40be237ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948b1a5-db82-42fc-a9b9-04a44230d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(text=['السلام عليكم ورحمة الله وبركاته'],file_name='I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ff277-a546-4e89-b9f5-19e387874217",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(text=['السلام عليكم ورحمة الله وبركاته'],num_inference_steps=40,controlnet_conditioning_step=50,image_size=[1024,512],file_name='I2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e41b02-a215-4931-b0fd-013f1abcbfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(text=['السلام عليكم ورحمة الله وبركاته'],num_inference_steps=40,controlnet_conditioning_step=20,image_size=[512,512],file_name='I3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0289b4-284e-4750-8935-6d427d90970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(prompt='A clearly visible street sign placed in the middle of a city road.',text=[ 'ورحمة الله وبركاته','السلام عليكم'],num_inference_steps=40,controlnet_conditioning_step=50,image_size=[1024,512],file_name='I4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec89c2a-81ad-4699-b26c-dc765c901a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(prompt='A clearly visible street sign placed in the middle of a city road.',text=['السلام عليكم ورحمة الله وبركاته'],num_inference_steps=40,controlnet_conditioning_step=50,image_size=[1024,512],file_name='I5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0709f99a-7dbc-478e-90fc-58319bfe6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(prompt='A clearly visible street sign placed in the middle of a city road.',text=['السلام عليكم'],num_inference_steps=30,controlnet_conditioning_step=50,image_size=[1024,512],file_name='I6')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70302a24-f86a-4b33-8e50-6541ff111d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(prompt='A clearly visible street sign placed in the middle of a city road.',text=['صباح الخير'],num_inference_steps=30,controlnet_conditioning_step=40,image_size=[1024,512],file_name='Good morning')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e8288-fd0b-4dba-bf49-a96e836413b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(prompt='A clearly visible street sign placed in the middle of a city road.',text=['مرحبا بك'],num_inference_steps=30,controlnet_conditioning_step=30,image_size=[1024,512],file_name='Welcome to you_CC30')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72466960-a83b-449d-b2f1-5010f861f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(prompt='A clearly visible street sign placed in the middle of a city road.',text=['مرحبا بك'],num_inference_steps=30,controlnet_conditioning_step=10,image_size=[1024,512],file_name='Welcome to you_cc10')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2314a27-0a9d-4970-9567-934f4a231199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_CC_loop(text=[\"hi!!\"],prompt='a street sign in city',num_inference_steps=20,controlnet_conditioning_step_list=[10,15,20,25,30,35,40],image_size=[1024,1024],file_name='result'):\n",
    "    ## set text content, position, color\n",
    "    \n",
    "    ## set resolution\n",
    "    width, height = image_size[0], image_size[1]\n",
    "\n",
    "    ## set font\n",
    "    font_path = \"./assets/Arial_Unicode.ttf\" # use your own font\n",
    "    font_size = 80 # it is recommended to use a font size >= 60\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    ## set text content, position, color\n",
    "    text_list = text\n",
    "    text_position_list = [(370, 200)]\n",
    "    text_color_list = [(255, 255, 255)]\n",
    "\n",
    "    # text_list = [\"Shakker Labs\"]\n",
    "    # text_position_list = [(270, 300)]\n",
    "    # text_color_list = [(255, 255, 255)]\n",
    "\n",
    "    # text_list = [\"Lovart AI\", \"Always Day 1\"]\n",
    "    # text_position_list = [(470, 300), (470, 400)]\n",
    "    # text_color_list = [(255, 255, 255), (255, 255, 255)]\n",
    "\n",
    "    # text_list = [\"以往不谏\", \"来者可追\"]\n",
    "    # text_position_list = [(200, 200), (200, 300)]\n",
    "    # text_color_list = [(255, 255, 255), (255, 255, 255)]\n",
    "\n",
    "    # text_list = [\"Shakker Labs\", \"RepText\"]\n",
    "    # text_position_list = [(200, 200), (200, 300)]\n",
    "    # text_color_list = [(255, 255, 255), (255, 255, 255)]\n",
    "\n",
    "    ## set controlnet conditions\n",
    "    control_image_list = [] # canny list\n",
    "    control_position_list = [] # position list\n",
    "    control_mask_list = [] # regional mask list\n",
    "    control_glyph_all = np.zeros([height, width, 3], dtype=np.uint8) # all glyphs\n",
    "    \n",
    "    ## handle each line of text\n",
    "    for text, text_position, text_color in zip(text_list, text_position_list, text_color_list):\n",
    "\n",
    "        ### glyph image, render text to black background\n",
    "        control_image_glyph = Image.new(\"RGB\", (width, height), (0, 0, 0))\n",
    "        draw = ImageDraw.Draw(control_image_glyph)\n",
    "        draw.text(text_position, text, font=font, fill=text_color)\n",
    "\n",
    "        ### get bbox\n",
    "        bbox = draw.textbbox(text_position, text, font=font)\n",
    "\n",
    "        ### position condition\n",
    "        control_position = np.zeros([height, width], dtype=np.uint8)\n",
    "        control_position[bbox[1]:bbox[3], bbox[0]:bbox[2]] = 255\n",
    "        control_position = Image.fromarray(control_position.astype(np.uint8))\n",
    "        control_position_list.append(control_position)\n",
    "\n",
    "        ### regional mask\n",
    "        control_mask_np = np.zeros([height, width], dtype=np.uint8)\n",
    "        control_mask_np[bbox[1]-5:bbox[3]+5, bbox[0]-5:bbox[2]+5] = 255\n",
    "        control_mask = Image.fromarray(control_mask_np.astype(np.uint8))\n",
    "        control_mask_list.append(control_mask)\n",
    "\n",
    "        ### accumulate glyph\n",
    "        control_glyph = np.array(control_image_glyph)\n",
    "        control_glyph_all += control_glyph\n",
    "\n",
    "        ### canny condition\n",
    "        control_image = canny(cv2.cvtColor(np.array(control_image_glyph), cv2.COLOR_RGB2BGR))\n",
    "        control_image = Image.fromarray(cv2.cvtColor(control_image, cv2.COLOR_BGR2RGB))\n",
    "        control_image_list.append(control_image)\n",
    "        \n",
    "    control_glyph_all = Image.fromarray(control_glyph_all.astype(np.uint8))\n",
    "    control_glyph_all = control_glyph_all.convert(\"RGB\")\n",
    "    # control_glyph_all.save(\"./results/control_glyph.jpg\")\n",
    "\n",
    "    # it is recommended to use words such 'sign', 'billboard', 'banner' in your prompt\n",
    "    # for Englith text, it helps if you add the text to the prompt\n",
    "    for text in text_list:\n",
    "        if not contains_chinese(text):\n",
    "            prompt += f\", '{text}'\"\n",
    "    prompt += \", filmfotos, film grain, reversal film photography\" # optional\n",
    "    print(prompt)\n",
    "\n",
    "    generator = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "    if not os.path.exists(\"./results\"):\n",
    "        os.makedirs(\"./results\")\n",
    "    for i in controlnet_conditioning_step_list:\n",
    "        image = pipe(\n",
    "            prompt,\n",
    "            control_image=control_image_list, # canny\n",
    "            control_position=control_position_list, # position\n",
    "            control_mask=control_mask_list, # regional mask\n",
    "            control_glyph=control_glyph_all, # as init latent, optional, set to None if not used\n",
    "            controlnet_conditioning_scale=1.0,\n",
    "            controlnet_conditioning_step=i,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=3.5,\n",
    "            generator=generator,\n",
    "        ).images[0]\n",
    "        image.save(f\"./results/{file_name+ str(i)}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8042561-5538-4470-8c72-2629df5c2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_CC_loop(text=[\"كيف حالك؟\"],image_size=[512,512],file_name='How are you?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d5950-095a-4b14-be00-2702fe967d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_CC_loop(text=[\"أهلاً وسهلاً\"],image_size=[512,512],file_name='You are most welcome')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a80fa4-e552-42d9-82a9-79a6f779e40e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
