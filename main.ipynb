{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b1dc3-1ec5-4aeb-bfd9-4cf6003e572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"RepText\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ae3ba-1484-4c44-8e4e-26e7aaad43d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ccf8ff-2d39-4ee5-9ee5-3d93776fe6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c855fe-941b-48a6-9acd-a6ecfc0cd920",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python infer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11490154-7ff5-4ddf-baad-90f110ea7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from controlnet_flux import FluxControlNetModel\n",
    "from pipeline_flux_controlnet import FluxControlNetPipeline\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "import os\n",
    "\n",
    "def contains_chinese(text):\n",
    "    if re.search(r'[\\u4e00-\\u9fff]', text):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def canny(img):\n",
    "    low_threshold = 50\n",
    "    high_threshold = 100\n",
    "    img = cv2.Canny(img, low_threshold, high_threshold)\n",
    "    img = img[:, :, None]\n",
    "    img = 255 - np.concatenate([img, img, img], axis=2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1056187-b7e7-4ade-818b-ce7e41b0caa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec78b2-a889-4d5b-8e03-00c6c7b4ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"black-forest-labs/FLUX.1-dev\"\n",
    "controlnet_model = \"Shakker-Labs/RepText\"\n",
    "\n",
    "controlnet = FluxControlNetModel.from_pretrained(controlnet_model, torch_dtype=torch.bfloat16)\n",
    "pipe = FluxControlNetPipeline.from_pretrained(\n",
    "    base_model, controlnet=controlnet, torch_dtype=torch.bfloat16\n",
    ").to(\"cuda\")\n",
    "\n",
    "## set resolution\n",
    "width, height = 1024, 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfccb56a-1cbb-4a78-bdd9-f3f657ea0ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text=\"hi!!\",prompt='a street sign in city'):\n",
    "    ## set text content, position, color\n",
    "    text_list = [text]\n",
    "    text_position_list = [(370, 200)]\n",
    "    text_color_list = [(255, 255, 255)]\n",
    "    \n",
    "    ## set controlnet conditions\n",
    "    control_image_list = [] # canny list\n",
    "    control_position_list = [] # position list\n",
    "    control_mask_list = [] # regional mask list\n",
    "    control_glyph_all = np.zeros([height, width, 3], dtype=np.uint8) # all glyphs\n",
    "    \n",
    "    ## handle each line of text\n",
    "    for text, text_position, text_color in zip(text_list, text_position_list, text_color_list):\n",
    "    \n",
    "        ### glyph image, render text to black background\n",
    "        control_image_glyph = Image.new(\"RGB\", (width, height), (0, 0, 0))\n",
    "        draw = ImageDraw.Draw(control_image_glyph)\n",
    "        draw.text(text_position, text, font=font, fill=text_color)\n",
    "        \n",
    "        ### get bbox\n",
    "        bbox = draw.textbbox(text_position, text, font=font)\n",
    "        \n",
    "        ### position condition\n",
    "        control_position = np.zeros([height, width], dtype=np.uint8)\n",
    "        control_position[bbox[1]:bbox[3], bbox[0]:bbox[2]] = 255\n",
    "        control_position = Image.fromarray(control_position.astype(np.uint8))\n",
    "        control_position_list.append(control_position)\n",
    "        \n",
    "        ### regional mask\n",
    "        control_mask_np = np.zeros([height, width], dtype=np.uint8)\n",
    "        control_mask_np[bbox[1]-5:bbox[3]+5, bbox[0]-5:bbox[2]+5] = 255\n",
    "        control_mask = Image.fromarray(control_mask_np.astype(np.uint8))\n",
    "        control_mask_list.append(control_mask)\n",
    "        \n",
    "        ### accumulate glyph\n",
    "        control_glyph = np.array(control_image_glyph)\n",
    "        control_glyph_all += control_glyph\n",
    "        \n",
    "        ### canny condition\n",
    "        control_image = canny(cv2.cvtColor(np.array(control_image_glyph), cv2.COLOR_RGB2BGR))\n",
    "        control_image = Image.fromarray(cv2.cvtColor(control_image, cv2.COLOR_BGR2RGB))\n",
    "        control_image_list.append(control_image)\n",
    "    \n",
    "    control_glyph_all = Image.fromarray(control_glyph_all.astype(np.uint8))\n",
    "    control_glyph_all = control_glyph_all.convert(\"RGB\")\n",
    "    # control_glyph_all.save(\"./results/control_glyph.jpg\")\n",
    "    \n",
    "    # it is recommended to use words such 'sign', 'billboard', 'banner' in your prompt\n",
    "    # for Englith text, it helps if you add the text to the prompt\n",
    "    \n",
    "    for text in text_list:\n",
    "        if not contains_chinese(text):\n",
    "            prompt += f\", '{text}'\"\n",
    "    prompt += \", filmfotos, film grain, reversal film photography\" # optional\n",
    "    print(prompt)\n",
    "\n",
    "    generator = torch.Generator(device=\"cuda\").manual_seed(42)\n",
    "\n",
    "    image = pipe(\n",
    "        prompt,\n",
    "        control_image=control_image_list, # canny\n",
    "        control_position=control_position_list, # position\n",
    "        control_mask=control_mask_list, # regional mask\n",
    "        control_glyph=control_glyph_all, # as init latent, optional, set to None if not used\n",
    "        controlnet_conditioning_scale=1.0,\n",
    "        controlnet_conditioning_step=30,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        num_inference_steps=30,\n",
    "        guidance_scale=3.5,\n",
    "        generator=generator,\n",
    "    ).images[0]\n",
    "\n",
    "    if not os.path.exists(\"./results\"):\n",
    "        os.makedirs(\"./results\")\n",
    "    image.save(f\"./results/result.jpg\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c1610-9866-4801-94eb-f40be237ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
