{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f3ae66",
   "metadata": {},
   "source": [
    "# RepText Arabic Training - Quick Start Guide\n",
    "\n",
    "This notebook demonstrates how to pretrain RepText for Arabic text generation.\n",
    "\n",
    "## Prerequisites\n",
    "- NVIDIA GPU with at least 24GB VRAM\n",
    "- Python 3.8+\n",
    "- CUDA 11.7+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b310268",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f599f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c883b",
   "metadata": {},
   "source": [
    "## Step 2: Download Arabic Fonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5deece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download recommended Arabic fonts from Google Fonts\n",
    "!python download_arabic_fonts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa043d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify fonts were downloaded\n",
    "import os\n",
    "fonts = [f for f in os.listdir('arabic_fonts') if f.endswith(('.ttf', '.otf'))]\n",
    "print(f\"Found {len(fonts)} fonts:\")\n",
    "for font in fonts:\n",
    "    print(f\"  - {font}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d34ac2",
   "metadata": {},
   "source": [
    "## Step 3: Test Font Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Test Arabic text rendering\n",
    "test_text = \"مرحبا بكم في RepText\"\n",
    "font_path = \"./arabic_fonts/Amiri-Regular.ttf\"\n",
    "\n",
    "img = Image.new('RGB', (600, 150), color='white')\n",
    "draw = ImageDraw.Draw(img)\n",
    "font = ImageFont.truetype(font_path, 60)\n",
    "draw.text((50, 40), test_text, font=font, fill='black')\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Arabic Text Rendering Test')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Arabic text rendering works correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c8234",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Training Dataset\n",
    "\n",
    "This will generate synthetic training samples with:\n",
    "- Glyph images (rendered Arabic text)\n",
    "- Position maps (location heatmaps)\n",
    "- Binary masks (text regions)\n",
    "- Canny edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For quick testing, use a small number of samples\n",
    "# For actual training, use 10000-50000\n",
    "NUM_SAMPLES = 100  # Change to 10000 for real training\n",
    "\n",
    "!python prepare_arabic_dataset.py \\\n",
    "    --output_dir ./arabic_training_data \\\n",
    "    --font_dir ./arabic_fonts \\\n",
    "    --text_file ./arabic_texts.txt \\\n",
    "    --num_samples {NUM_SAMPLES} \\\n",
    "    --width 1024 \\\n",
    "    --height 1024 \\\n",
    "    --min_font_size 60 \\\n",
    "    --max_font_size 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02c90d2",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Training Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load a sample\n",
    "sample_dir = \"./arabic_training_data/sample_000000\"\n",
    "\n",
    "# Load images\n",
    "glyph = Image.open(f\"{sample_dir}/glyph.png\")\n",
    "position = Image.open(f\"{sample_dir}/position.png\")\n",
    "mask = Image.open(f\"{sample_dir}/mask.png\")\n",
    "canny = Image.open(f\"{sample_dir}/canny.png\")\n",
    "\n",
    "# Load metadata\n",
    "with open(f\"{sample_dir}/metadata.json\", 'r', encoding='utf-8') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "axes[0, 0].imshow(glyph)\n",
    "axes[0, 0].set_title(f\"Glyph: {metadata['text']}\")\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(position)\n",
    "axes[0, 1].set_title(\"Position Map\")\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(mask, cmap='gray')\n",
    "axes[1, 0].set_title(\"Text Mask\")\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(canny)\n",
    "axes[1, 1].set_title(\"Canny Edges\")\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.suptitle(f\"Training Sample - Font Size: {metadata['font_size']}px\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f26e8c",
   "metadata": {},
   "source": [
    "## Step 6: Test Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fdd7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arabic_dataset import create_dataloaders\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    data_dir='./arabic_training_data',\n",
    "    batch_size=2,\n",
    "    num_workers=0,\n",
    "    image_size=(1024, 1024),\n",
    "    train_ratio=0.9\n",
    ")\n",
    "\n",
    "# Test loading a batch\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "print(\"Batch contents:\")\n",
    "print(f\"  Glyph shape: {batch['glyph'].shape}\")\n",
    "print(f\"  Position shape: {batch['position'].shape}\")\n",
    "print(f\"  Mask shape: {batch['mask'].shape}\")\n",
    "print(f\"  Canny shape: {batch['canny'].shape}\")\n",
    "print(f\"  Text samples: {batch['text']}\")\n",
    "print(f\"  Font sizes: {batch['font_size']}\")\n",
    "print(\"\\n✓ Dataset loading works correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde47a3d",
   "metadata": {},
   "source": [
    "## Step 7: Configure Accelerate for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f74d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d148693",
   "metadata": {},
   "source": [
    "## Step 8: Review Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa0ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('train_config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdb1d01",
   "metadata": {},
   "source": [
    "## Step 9: Launch Training\n",
    "\n",
    "**Note:** Training takes a long time. You may want to run this in a terminal instead of notebook.\n",
    "\n",
    "For terminal:\n",
    "```bash\n",
    "accelerate launch train_arabic.py --config train_config.yaml\n",
    "```\n",
    "\n",
    "Or use the automated script:\n",
    "```bash\n",
    "./train_arabic.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ce32ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For notebook training (not recommended for long training runs)\n",
    "# Uncomment to run:\n",
    "# !accelerate launch train_arabic.py --config train_config.yaml\n",
    "\n",
    "print(\"It's recommended to run training in a terminal or tmux session:\")\n",
    "print(\"  accelerate launch train_arabic.py --config train_config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2da5d32",
   "metadata": {},
   "source": [
    "## Step 10: Monitor Training (Optional - with W&B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f83bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install wandb\n",
    "# !pip install wandb\n",
    "# !wandb login\n",
    "\n",
    "# Then run with --use_wandb flag:\n",
    "# !accelerate launch train_arabic.py --config train_config.yaml --use_wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdbe107",
   "metadata": {},
   "source": [
    "## Step 11: Test Your Trained Model\n",
    "\n",
    "After training completes, test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb92100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from controlnet_flux import FluxControlNetModel\n",
    "from pipeline_flux_controlnet import FluxControlNetPipeline\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load your trained model\n",
    "base_model = \"black-forest-labs/FLUX.1-dev\"\n",
    "controlnet_model = \"./output/arabic_reptext/final_model\"  # or checkpoint-XXXX\n",
    "\n",
    "print(\"Loading models...\")\n",
    "controlnet = FluxControlNetModel.from_pretrained(\n",
    "    controlnet_model, \n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "pipe = FluxControlNetPipeline.from_pretrained(\n",
    "    base_model, \n",
    "    controlnet=controlnet, \n",
    "    torch_dtype=torch.bfloat16\n",
    ").to(\"cuda\")\n",
    "\n",
    "print(\"✓ Models loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9158329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an image with Arabic text\n",
    "# (Use the inference code from infer.py)\n",
    "\n",
    "print(\"Ready to generate images with Arabic text!\")\n",
    "print(\"See infer.py for complete inference examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e39d01f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've completed:\n",
    "✅ Installed dependencies\n",
    "✅ Downloaded Arabic fonts\n",
    "✅ Prepared training dataset\n",
    "✅ Tested dataset loading\n",
    "✅ Configured training\n",
    "\n",
    "Next steps:\n",
    "1. Increase `NUM_SAMPLES` to 10000+ for real training\n",
    "2. Run training in a terminal session\n",
    "3. Monitor with W&B or TensorBoard\n",
    "4. Test your trained model\n",
    "\n",
    "For detailed documentation, see [TRAINING_GUIDE.md](TRAINING_GUIDE.md)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
